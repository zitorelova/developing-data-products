pnorm(72, 80, 10, lower.tail=T)
# Find plain confidence interval using t dist
mu <- 1100
sigma <- 20
n <- 20
ci <- mu + c(-1,1) * qt(0.975, df=n-1) * sigma / sqrt(n)
ci
ppois(9, 5*3, lower.tail = T)
?qnorm
qnorm(0.85, 1100, sd=75)
# Use for independent t test with different variance
nnew <- 9
nold <- 9
mu.new <- -3
mu.old <- 1
sd.new <- 1.5
sd.old <- 1.8
sp <- sqrt(((nnew - 1) * sd.new^2 + (nold - 1) * sd.old^2) / (nnew+nold-2))
ci <- (mu.new - mu.old + c(-1,1) * qt(.95,nnew+nold-2) * sp * sqrt(1/nnew + 1/nold))
ci
x <- 2:5
p <- x/sum(x)
temp <- rbind(x,p)
temp
sum(p*x)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
# Question 7
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
reg <- glm(y ~x)
reg$coefficients
# Question 9
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
x2 <- x**2
# Question 6
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
x_normed <- (x - mean(x)) / sd(x)
x_normed
# Question 3
data(mtcars)
reg <- glm(mtcars$mpg ~ mtcars$wt)
reg$coefficients
reg <- glm(mtcars$mpg ~ mtcars$wt)
1.5*0.4
# Question 2
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
reg <- glm(y ~ x)
reg$coefficients
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mu <- c(0.300, 0.1471, 0.0025, 1.077)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mu <- c(0.300, 0.1471, 0.0025, 1.077)
for(i in length(mu)){
print(w[i] * (x - mu[i])**2)
}
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
x2 <- x**2
y <- x - x2
y
mu <- sum(x*w) / sum(w)
mu
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mu <- sum(x*w) / sum(w)
mu
reg <- lm(y ~ x - 1)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
reg <- lm(y ~ x - 1)
reg$coefficients
library(swirl)
swirl()
install_course("Regression Models")
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
reg <- lm(y ~ x)
reg
str(reg)
summary(reg)
mtcars
reg <- lm(mtcars$mpg ~ mtcars$wt)
summary(reg)
data(mtcars)
head(mtcars)
help(mtcars)
library(ggplot2)
mtcars$am <- as.factor(mtcars$am)
str(mtcars)
g <- ggplot(data=mtcars, aes(y=mpg, x=am), fill=am)
g
g <- ggplot(data=mtcars, aes(y=mpg, x=am), fill=am)
g <- g + geom_boxplot()
g
mtcars %>% group_by(am)
library(dplyr)
mtcars %>% group_by(am)
?summarize
mtcars %>% group_by(am) %>% summarize(mpg, mean)
mtcars %>% group_by(am) %>% summarize(mean(mpg))
library(dplyr)
library(UsingR)
install.packages("UsingR")
library(MASS)
?cbind
spline_term = x * (x>0)
x <- -5:5
x
spline_term = x * (x>0)
spline_term
cbind(1, x, spline_term)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
fit
summary(fit)
coef(summary(fit))
coefTab <- coef(summary(fit))
coefTab[2, 4]
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
influence.measures(fit)
influence.measures(fit)$infmat[5, 'dfb.x']
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y~x)
influence.measures(fit)
data("InsectSprays")
fit = glm(InsectSprays$count ~factor(InsectSprays$spray)-1,family='poisson')
summary(fit)
summary(fit)$coeff[,1]
coeff3 <- summary(fit)$coeff[,1]
coeff3[3]
exp(coeff3[1] - coeff3[3]
exp(coeff3[1] - coeff3[3])
exp(coeff3[1] - coeff3[3])
x <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
y <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
fit
resid(fit)
sd(resid(fit))
fit$sigma
summary(fit)$sigma
x <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
y <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
fit <- lm(y ~ x)
summary(fit)
x <- c(0.8, 0.45, 0.50, 0.73, 0.36, 0.58, 0.60, 1.85, 0.44, 1.42)
mean(x)
install.packages('caret')
install.packages('rattle')
library(rattle)
library(caret)
train <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"),header=TRUE)
dim(train)
sum(is.na(train))
which(colSums(is.na(train)))
which(colSums(is.na(train))[1])
test <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"),header=TRUE)
dim(test)
which(colSums(is.na(train) | train =="") > 0.9*dim(test)[1])
train[, -rm]
rm <- which(colSums(is.na(train) | train =="") > 0.9*dim(test)[1])
train[, -rm]
new_train <- train[, -rm]
new_train <- new_train[, -c(1:7)]
names(train)
train <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"),header=TRUE)
dim(train)
test <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"),header=TRUE)
dim(test)
rm_train <- which(colSums(is.na(train) | train =="") > 0.9*dim(train)[1])
rm_test <- which(colSums(is.na(train) | train =="") > 0.9*dim(test)[1])
new_train <- train[, -rm_train]
new_train <- new_train[, -c(1:7)]
new_test <- test[, -rm_test]
new_test <- new_test[, -c(1:7)]
set.seed(42)
idx_train <- createDataPartition(new_train$classe, p=0.75, list=F)
train1 <- new_train[idx_train,]
test1 <- new_train[-idx_train,]
dim(test1)
dim(train1)
trControl <- trainControl(method='cv', number=5)
CT_mod <- train(classe~., data=new_train, method='rpart', trControl=trControl)
install.packages("e1071", dependencies = T)
CT_mod <- train(classe~., data=new_train, method='rpart', trControl=trControl)
fancyRpartPlot(CT_mod$finalModel)
trainpred <- predict(CT_model, newdata=test1)
trainpred <- predict(CT_mod, newdata=test1)
cm <- confusionMatrix(test1$classe, trainpred)
cm$table
cm$overall[1]
trControl <- trainControl(method='cv', number=5)
CT_mod <- train(classe~., data=train1, method='rpart', trControl=trControl)
fancyRpartPlot(CT_mod$finalModel)
trainpred <- predict(CT_mod, newdata=test1)
cm <- confusionMatrix(test1$classe, trainpred)
cm$table
cm$overall[1]
RF_mod <- train(class~., data=train1, method='rf', trControl=trControl, verbose=F)
RF_mod <- train(classe~., data=train1, method='rf', trControl=trControl, verbose=F)
library(caret)
library(rattle)
TrainData <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"),header=TRUE)
dim(TrainData)
TestData <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"),header=TRUE)
dim(TestData)
indColToRemove <- which(colSums(is.na(TrainData) |TrainData=="")>0.9*dim(TrainData)[1])
TrainDataClean <- TrainData[,-indColToRemove]
TrainDataClean <- TrainDataClean[,-c(1:7)]
dim(TrainDataClean)
indColToRemove <- which(colSums(is.na(TestData) |TestData=="")>0.9*dim(TestData)[1])
TestDataClean <- TestData[,-indColToRemove]
TestDataClean <- TestDataClean[,-1]
dim(TestDataClean)
set.seed(12345)
inTrain1 <- createDataPartition(TrainDataClean$classe, p=0.75, list=FALSE)
Train1 <- TrainDataClean[inTrain1,]
Test1 <- TrainDataClean[-inTrain1,]
dim(Train1)
dim(Test1)
trControl <- trainControl(method="cv", number=5)
model_CT <- train(classe~., data=Train1, method="rpart", trControl=trControl)
fancyRpartPlot(model_CT$finalModel)
trainpred <- predict(model_CT,newdata=Test1)
confMatCT <- confusionMatrix(Test1$classe,trainpred)
# display confusion matrix and model accuracy
confMatCT$table
confMatCT$overall[1]
model_RF <- train(classe~., data=Train1, method="rf", trControl=trControl, verbose=FALSE)
print(model_RF)
plot(model_RF,main="Accuracy of Random forest model by number of predictors")
trainpred <- predict(model_RF,newdata=Test1)
confMatRF <- confusionMatrix(Test1$classe,trainpred)
# display confusion matrix and model accuracy
confMatRF$table
confMatRF$overall[1]
names(model_RF$finalModel)
plot(model_RF$finalModel,main="Model error of Random forest model by number of trees")
MostImpVars <- varImp(model_RF)
MostImpVars
model_GBM <- train(classe~., data=Train1, method="gbm", trControl=trControl, verbose=FALSE)
print(model_GBM)
plot(model_GBM)
trainpred <- predict(model_GBM,newdata=Test1)
confMatGBM <- confusionMatrix(Test1$classe,trainpred)
confMatGBM$table
confMatGBM$overall[1]
FinalTestPred <- predict(model_RF,newdata=TestDataClean)
FinalTestPred
summary(TrainData)
str(Train1)
library(rpart)
library(caret)
library(gbm)
set.seed(3433)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., training, method = "rf")
mod_gbm <- train(diagnosis ~ ., training, method = "gbm", verbose = FALSE)
mod_lda <- train(diagnosis ~ ., training, method = "lda")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain, ]
testing = concrete[-inTrain, ]
set.seed(233)
modlasso <- train(CompressiveStrength ~ ., training, method = "lasso")
plot.enet(modlasso$finalModel, xvar="penalty", use.color=TRUE)
set.seed(233)
modlasso <- train(CompressiveStrength ~ ., training, method = "lasso")
plot.enet(modlasso$finalModel, xvar="penalty", use.color=TRUE)
library(elasticnet)
plot.enet(modlasso$finalModel, xvar="penalty", use.color=TRUE)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages("ElemStatLearn")
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(url, destfile = "gaData.csv")
dat = read.csv("gaData.csv")
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
modfc <- bats(tstrain)
predts <- forecast(modfc, level = 90, nrow(testing))
fslower95 <- predts$lower
fsupper95 <- predts$upper
table ((testing$visitsTumblr>fslower95) & (testing$visitsTumblr<fsupper95))
install.packages("forecast")
library(forecast)
modfc <- bats(tstrain)
predts <- forecast(modfc, level = 90, nrow(testing))
fslower95 <- predts$lower
fsupper95 <- predts$upper
table ((testing$visitsTumblr>fslower95) & (testing$visitsTumblr<fsupper95))
218/nrow(testing)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[,grep("^IL", names(training))]
procTrain <- preProcess(trainingIL, method = "pca", thresh = 0.7 )
procTrain
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
install.packages("e1071")
install.packages("e1071")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
library(e1071)
set.seed(325)
fit <- svm(CompressiveStrength ~ ., training)
predsvm <- predict(fit, testing)
error = predsvm - testing$CompressiveStrength
error
abs(error)
mean(abs(error))
install.packages("shiny")
library(shiny)
library(shiny)
runApp('MyApp')
runApp('MyApp')
library(shiny)
runApp('MyApp')
shiny::runApp('MyApp')
runApp('MyApp')
?builder
runApp('MyApp')
runApp('MyApp')
runApp('MyApp')
runApp('MyApp')
runApp('MyApp')
runApp('MyApp')
runApp('MyApp')
ppois?
:
?ppois
ppois(q=1/3, lambda=1)
ppois(q=1/3, lambda=1, lower.tail=F)
?power
1^5
2^2
1-(0.005^1/3)
0.005^1/3
1-(0.005^(1/3))
?root
?nthroot
4^1/2
27^1/3
27^(1/3)
(0.005^(1/3))
1-(0.05^(1/3))
?qpois
qpois(1/3, 1)
qpois(0.3, 1, lower.tail=F)
dpois(0.3, 1)
dpois(1/3, 1)
ppois(1/3, 1)
ppois(1/3, 1, lower.tail=F)
ppois(1/2, 1, lower.tail=F)
ppois(1, 1, lower.tail=F)
log(0.95)
-log(0.95)
0.95
0.95/30
30/0.95
lam -> 30/0.95
lam <- 30/0.95
ppois(10, lam)
ppois(10, lam, lower.tail=F)
ppois(1, 2)
2^1*exp^-2
e
2^1*exp(1)^-2
(2^1*exp(1)^-2) / 1
dpois(1, 2)
3^-2
3/2
3/(1/2)
3^-2
1/(3^2)
library(leaflet)
my_map <- leaflet() %>% addTiles()
EiffelTour <- c("<a href= 'http://www.toureiffel.paris' >Eiffel Tour</a>")
leaflet() %>%
addTiles() %>% addMarkers(lat=48.858053, lng=2.294289, popup=EiffelTour)
shiny::runApp('MyApp')
runApp('MyApp')
runApp('MyApp')
runApp('MyApp')
knitr::opts_chunk$set(echo = TRUE)
inputPanel(
selectInput("n_breaks", label = "Number of bins:",
choices = c(10, 20, 35, 50), selected = 20),
sliderInput("bw_adjust", label = "Bandwidth adjustment:",
min = 0.2, max = 2, value = 1, step = 0.2)
)
renderPlot({
hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),
xlab = "Duration (minutes)", main = "Geyser eruption duration")
dens <- density(faithful$eruptions, adjust = input$bw_adjust)
lines(dens, col = "blue")
})
shinyAppDir(
system.file("examples/06_tabsets", package = "shiny"),
options = list(
width = "100%", height = 550
)
)
knitr::opts_chunk$set(echo = TRUE)
library(leaflet)
my_map <- leaflet() %>%
addTiles()
library(leaflet)
my_map <- leaflet() %>%
addTiles()
my_map
shiny::runApp('MyApp')
runApp('MyApp')
runApp('MyApp')
shiny::runApp('MyApp')
colSums
lm
dgamma
predict()
?predict
?stats
install.packages("plotly")
shiny::runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
install.packages('shinyBS')
runApp('Documents/developing-data-products/ddp_week4')
install.packages('shinythemes')
runApp('Documents/developing-data-products/ddp_week4')
head(mtcars)
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
head(mtcars)
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
head(mtcars)
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products/ddp_week4')
runApp('Documents/developing-data-products')
runApp('Documents/developing-data-products')
runApp('Documents/developing-data-products')
runApp('Documents/developing-data-products')
runApp('Documents/developing-data-products')
runApp('Documents/developing-data-products')
